
<section xml:id="fittingALineByLSR">
  <title>Fitting a line by least squares regression MISSINGVIDEOLINK</title>
  <introduction>
    <p>
      <index><main>least squares regression</main></index>
    </p>

    <p>
      Fitting linear models by eye is open to criticism since it is based on an individual preference. In this section, we use <em>least squares regression</em> as a more rigorous approach.
    </p>

    <p>
      This section considers family income and gift aid data from a random sample of fifty students in the 2011 freshman class of Elmhurst College in Illinois.<fn>These data were sampled from a table of data for all freshman from the 2011 class at Elmhurst College that accompanied an article titled <em>What Students Really Pay to Go to College</em> published online by <em>The<nbsp />Chronicle of Higher Education</em>: MISSINGoiRedirect</fn> Gift aid is financial aid that does not need to be paid back, as opposed to a loan. A scatterplot of the data is shown in <xref ref="elmhurstScatterW2Lines">Figure</xref> along with two linear fits. The lines follow a negative trend in the data; students who have higher family incomes tended to have lower gift aid from the university.
    </p>

    <figure xml:id="elmhurstScatterW2Lines" >
      <caption>Gift aid and family income for a random sample of 50 freshman students from Elmhurst College. Two lines are fit to the data, the solid line being the <em>least squares line</em>.</caption>
      <image width="75%" source="images/elmhurstScatterW2Lines.png" />
    </figure>

    <exercise>
      <statement>
        <p>
          Is the correlation positive or negative in <xref ref="elmhurstScatterW2Lines">Figure</xref>?
        </p>
      </statement>
      <hint>
        <p>
          Larger family incomes are associated with lower amounts of aid, so the correlation will be negative. Using a computer, the correlation can be computed: -0.499.
        </p>
      </hint>
    </exercise>
  </introduction>

  <subsection>
    <title>An objective measure for finding the best line</title>
    <p>
      We begin by thinking about what we mean by <q>best</q>. Mathematically, we want a line that has small residuals. Perhaps our criterion could minimize the sum of the residual magnitudes:
      <md>
        <mrow>|y_1 - \hat{y}_1| + |y_2-\hat{y}_2| + \dots + |y_n-\hat{y}_n|</mrow>
      </md>
      which we could accomplish with a computer program. The resulting dashed line shown in <xref ref="elmhurstScatterW2Lines">Figure</xref> demonstrates this fit can be quite reasonable. However, a more common practice is to choose the line that minimizes the sum of the squared residuals:
      <md>
        <mrow>(y_1 - \hat{y}_1)^2 + (y_2-\hat{y}_2)^2+ \dots + (y_n-\hat{y}_n)^2</mrow>
      </md>
    </p>

    <p>
      The line that minimizes this <term>least squares criterion</term> is represented as the solid line in <xref ref="elmhurstScatterW2Lines">Figure</xref>. This is commonly called the <term>least squares line</term>. The following are three possible reasons to choose Criterion<nbsp /><xref ref="sumOfSquaresForResiduals" /> over Criterion<nbsp /><xref ref="sumOfAbsoluteValueOfResiduals" />:
      <ol>
        <li>
          <p>
            It is the most commonly used method.
          </p>
        </li>

        <li>
          <p>
            Computing the line based on Criterion<nbsp /><xref ref="sumOfSquaresForResiduals" /> is much easier by hand and in most statistical software.
          </p>
        </li>

        <li>
          <p>
            In many applications, a residual twice as large as another residual is more than twice as bad. For example, being off by 4 is usually more than twice as bad as being off by 2. Squaring the residuals accounts for this discrepancy.
          </p>
        </li>
      </ol>
    </p>

    <p>
      The first two reasons are largely for tradition and convenience; the last reason explains why Criterion<nbsp /><xref ref="sumOfSquaresForResiduals" /> is typically most helpful.<fn>There are applications where Criterion<nbsp /><xref ref="sumOfAbsoluteValueOfResiduals" /> may be more useful, and there are plenty of other criteria we might consider. However, this book only applies the least squares criterion.</fn>
    </p>
  </subsection>

  <subsection>
    <title>Conditions for the least squares line</title>
    <p>
    When fitting a least squares line, we generally require
    <ul>
      <li>
      <title>Linearity.</title>
      <p>
      The data should show a linear trend.  If there is a nonlinear trend (e.g. left panel of <xref ref="whatCanGoWrongWithLinearModel">Figure</xref>), an advanced regression method from another book or later course should be applied.
        </p>
      </li>

      <li>
      <title>Nearly normal residuals.</title>
      <p>
      Generally the residuals must be nearly normal.
      When this condition is found to be unreasonable, it is usually because of outliers or concerns about influential points, which we  will discuss in greater depth in <xref ref="typesOfOutliersInLinearRegression">Section</xref>. An example of non-normal residuals is shown in the second panel of <xref ref="whatCanGoWrongWithLinearModel">Figure</xref>.
        </p>
      </li>

      <li>
      <title>Constant variability.</title>
      <p>
        The variability of points around the least squares line remains roughly constant. An example of non-constant variability is shown in the third panel of <xref ref="whatCanGoWrongWithLinearModel">Figure</xref>.
          </p>
        </li>
      </ul>
    </p>

    <p>
      These conditions are best checked using a residual plot. If a residual plot has no pattern, such as a U-shape or the presence of outliers or non-constant variability in the residuals, then the conditions above may be considered to be satisfied.
    </p>

    <aside>
      <title>Use a residual plot to determine if a linear model is appropriate</title>
      <p>
        When a residual plot appears as a random cloud of points, a linear model is generally appropriate. If a residual plot has any type of pattern, a linear model is not appropriate.
      </p>
    </aside>
    <p>
      Be cautious about applying regression to data collected sequentially in what is called a <term>time series</term>. Such data may have an underlying structure that should be considered in a model and analysis.
    </p>

    <figure xml:id="whatCanGoWrongWithLinearModel" >
      <caption>Four examples showing when the methods in this chapter are insufficient to apply to the data. In the left panel, a straight line does not fit the data. In the second panel, there are outliers; two points on the left are relatively distant from the rest of the data, and one of these points is very far away from the line. In the third panel, the variability of the data around the line increases with larger values of <m>x</m>. In the last panel, a time series data set is shown, where successive observations are highly correlated.</caption>
      <image width="73%" source="images/whatCanGoWrongWithLinearModel.png" />
    </figure>

    <exercise>
      <statement>
        <p>
          Should we have concerns about applying least squares regression to the Elmhurst data in <xref ref="elmhurstScatterW2Lines">Figure</xref>?
        </p>
      </statement>
      <hint>
        <p>
          The trend appears to be linear, the data fall around the line with no obvious outliers, the variance is roughly constant. These are also not time series observations. Least squares regression can be applied to these data.
        </p>
      </hint>
    </exercise>
  </subsection>

  <subsection xml:id="findingTheLeastSquaresLineSection">
    <title>Finding the least squares line</title>
    <p>
      For the Elmhurst data, we could write the equation of the least squares regression line as
      <md>
        <mrow>\widehat{aid} = \beta_0 + \beta_{1}\times family\_income</mrow>
      </md>
    </p>

    <p>
      Here the equation is set up to predict gift aid based on a student's family income, which would be useful to students considering Elmhurst. These two values, <m>\beta_0</m> and <m>\beta_1</m>, are the <em>parameters</em> of the regression line.
    </p>

    <p>
      As in Chapters<nbsp />4-6, the parameters are estimated using observed data. In practice, this estimation is done using a computer in the same way that other estimates, like a sample mean, can be estimated using a computer or calculator. However, we can also find the parameter estimates by applying two properties of the least squares line:
      <ul>
        <li>
          <p>
            The slope of the least squares line can be estimated by
            <md>
              <mrow>b_1 = r\frac{s_y}{s_x}</mrow>
            </md>
            where <m>r</m> is the correlation between the two variables, and <m>s_x</m> and <m>s_y</m> are the sample standard deviations of the explanatory variable 
            and response
            , respectively.
          </p>
        </li>

        <li>
          <p>
            If <m>\bar{x}</m> is the mean of the horizontal variable (from the data) and <m>\bar{y}</m> is the mean of the vertical variable, then the point <m>(\bar{x}, \bar{y})</m> is on the least squares line. Plugging this point in for <m>x</m> and <m>y</m> in the least squares equation and solving for <m>b_0</m> gives
            <md>
              <mrow>\bar{y} \amp = b_0 + b_1\bar{x}
              \amp \amp b_0=\bar{y}-b_1\bar{x}</mrow>
            </md>
            When solving for the <m>y</m>-intercept, first find the slope, <m>b_1</m>, and plug the slope and the point <m>(\bar{x}, \bar{y})</m> into the least squares equation.
          </p>
        </li>
      </ul>
    </p>

    <p>
      <fn>

      <m>b_0, b_1</m>
       Sample
      estimates
       of <m>\beta_0</m>, <m>\beta_1</m></fn>We use <m>b_0</m> and <m>b_1</m> to represent the point estimates of the parameters <m>\beta_0</m> and <m>\beta_1</m>.
    </p>
    <exercise>
      <statement>
        <p>
          <xref ref="summaryStatsOfSATGPAData">Table</xref> shows the sample means for the family income and gift aid as <dollar />101,800 and <dollar />19,940, respectively. Plot the point <m>(101.8, 19.94)</m> on <xref ref="elmhurstScatterW2Lines">Figure</xref> to verify it falls on the least squares line (the solid line).
        </p>
      </statement>
      <hint>
        <p>
          If you need help finding this location, draw a straight line up from the x-value of 100 (or thereabout). Then draw a horizontal line at 20 (or thereabout). These lines should intersect on the least squares line.
        </p>
      </hint>
    </exercise>

    <table xml:id="summaryStatsOfSATGPAData" >
      <caption>Summary statistics for family income and gift aid.</caption>
      <tabular>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-4mm}</cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{0.4mm}</cell>
          <cell><nbsp /><nbsp />family income, in <dollar />1000s (<q><m>x</m></q>)</cell>
          <cell><nbsp /><nbsp />gift aid, in <dollar />1000s (<q><m>y</m></q>)</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-3.9mm}</cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>mean</cell>
          <cell><m>\bar{x} = 101.8</m></cell>
          <cell><m>\bar{y} = 19.94</m></cell>
        </row>
        <row>
          <cell>sd</cell>
          <cell><m>s_x = 63.2</m></cell>
          <cell><m>s_y = 5.46</m>\vspace{0.4mm}</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-4mm}<nbsp /></cell>
          <cell></cell>
        </row>
        <row>
          <cell></cell>
          <cell><m>r=-0.499</m></cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
      </tabular>
    </table>

    <exercise xml:id="findingTheSlopeOfTheLSRLineForIncomeAndAid">
      <statement>
        <p>
          Using the summary statistics in <xref ref="summaryStatsOfSATGPAData">Table</xref>, compute the slope and <m>y</m>-intercept for the regression line of gift aid against family income. Write the equation of the regression line.<fn>Apply Equations<nbsp /><xref ref="slopeOfLSRLine" /> and<nbsp /><xref ref="interceptOfLSRLine" /> with the summary statistics from <xref ref="summaryStatsOfSATGPAData">Table</xref> to compute the slope and <m>y</m>-intercept:
          <md>
            <mrow>b_1 \amp = r\frac{s_y}{s_x} = (-0.499)\frac{5.46}{63.2} = -0.0431</mrow>
            <mrow>b_0 \amp  = \bar{y} - b_1\bar{x} = 19.94 - (-0.0431)(101.8) = 24.3</mrow>
            <mrow>\hat{y}\amp =24.3 - 0.0431x
              \qquad\text{ or } \qquad
              \widehat{aid} = 24.3 - 0.0431 \text{ family\_income }</mrow>
          </md>
          </fn>
        </p>
      </statement>
    </exercise>
    <p>
      We mentioned earlier that a computer is usually used to compute the least squares line. A summary table based on computer output is shown in <xref ref="rOutputForIncomeAidLSRLine">Table</xref> for the Elmhurst data. The first column of numbers provides estimates for <m>{b}_0</m> and <m>{b}_1</m>, respectively. Compare these to the result from Guided <xref ref="findingTheSlopeOfTheLSRLineForIncomeAndAid">Practice</xref>.
    </p>

    <table xml:id="rOutputForIncomeAidLSRLine" >
      <caption>Summary of least squares fit for the Elmhurst data. Compare the parameter estimates in the first column to the results of Guided <xref ref="findingTheSlopeOfTheLSRLineForIncomeAndAid">Practice</xref>.</caption>
      <tabular>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-3.7mm}</cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell></cell>
          <cell>Estimate</cell>
          <cell>Std. Error</cell>
          <cell>t value</cell>
          <cell>Pr(<m>></m><m>|</m>t<m>|</m>)</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-3.6mm}</cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>(Intercept)</cell>
          <cell>24.3193</cell>
          <cell>1.2915</cell>
          <cell>18.83</cell>
          <cell>0.0000</cell>
        </row>
        <row>
          <cell>family_income</cell>
          <cell>-0.0431</cell>
          <cell>0.0108</cell>
          <cell>-3.98</cell>
          <cell>0.0002</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
      </tabular>
    </table>

    <example>
      <statement>
        <p>
          Examine the second, third, and fourth columns in <xref ref="rOutputForIncomeAidLSRLine">Table</xref>. Can you guess what they represent?
        </p>
      </statement>
      <answer>
        <p>
          We'll describe the meaning of the columns using the second row, which corresponds to<nbsp /><m>\beta_1</m>. The first column provides the point estimate for <m>\beta_1</m>, as we calculated in an earlier example: -0.0431. The second column is a standard error for this point estimate: 0.0108. The third column is a <m>T</m> test statistic for the null hypothesis that <m>\beta_1 = 0</m>: <m>T=-3.98</m>. The last column is the p-value for the <m>T</m> test statistic for the null hypothesis <m>\beta_1=0</m> and a two-sided alternative hypothesis: 0.0002. We will get into more of these details in <xref ref="inferenceForLinearRegression">Section</xref>.
        </p>
      </answer>
    </example>

    <example>
      <statement>
        <p>
          Suppose a high school senior is considering Elmhurst College. Can she simply use the linear equation that we have estimated to calculate her financial aid from the university?
        </p>
      </statement>
      <answer>
        <p>
          She may use it as an estimate, though some qualifiers on this approach are important. First, the data all come from one freshman class, and the way aid is determined by the university may change from year to year. Second, the equation will provide an imperfect estimate. While the linear equation is good at capturing the trend in the data, no individual student's aid will be perfectly predicted.
          <index><main>least squares regression</main></index>
        </p>
      </answer>
    </example>
  </subsection>

  <subsection>
    <title>Interpreting regression line parameter estimates</title>
    <p>
      <index><main>least squares regression</main><sub>interpreting parameters</sub></index>
    </p>

    <p>
      Interpreting parameters in a regression model is often one of the most important steps in the analysis.
    </p>

    <example>
      <statement>
        <p>
          The slope and intercept estimates for the Elmhurst data are -0.0431 and 24.3. What do these numbers really mean?
        </p>
      </statement>
      <answer>
        <p>
          Interpreting the slope parameter is helpful in almost any application. For each additional <dollar />1,000 of family income, we would expect a student to receive a net difference of <m>\dollar\text{ 1,000 } \times (-0.0431) = -\dollar43.10</m> in aid on average, i.e. <dollar />43.10 <em>less</em>. Note that a higher family income corresponds to less aid because the coefficient of family income is negative in the model. We must be cautious in this interpretation: while there is a real association, we cannot interpret a causal connection between the variables because these data are observational. That is, increasing a student's family income may not cause the student's aid to drop. (It would be reasonable to contact the college and ask if the relationship is causal, i.e. if Elmhurst College's aid decisions are partially based on students' family income.)
        </p>

        <p>
          The estimated intercept <m>b_0=24.3</m> (in <dollar />1000s) describes the average aid if a student's family had no income. The meaning of the intercept is relevant to this application since the family income for some students at Elmhurst is <dollar />0. In other applications, the intercept may have little or no practical value if there are no observations where <m>x</m> is near zero.
        </p>
      </answer>
    </example>

    <definition>
      <title>Interpreting parameters in a linear model</title>
      <statement>
        <ul>
          <li>
            <p>
              The slope, <m>b_1</m>, describes the average increase or decrease in the <m>y</m> variable if the explanatory variable <m>x</m> is one unit larger.
            </p>
          </li>

          <li>
            <p>
              The y-intercept, <m>b_0</m>, describes the average or predicted outcome of <m>y</m> if <m>x=0</m>.  The linear model must be valid all the way to <m>x=0</m> for this to make sense, which in many applications is not the case.
            </p>
          </li>
        </ul>
      </statement>
    </definition>

    <p>
      <index><main>least squares regression</main><sub>interpreting parameters</sub></index>
    </p>
  </subsection>

  <subsection>
    <title>Extrapolation is treacherous</title>
    <p>
      <index><main>least squares regression</main><sub>extrapolation</sub></index>
    </p>

    <p>
      <em> When those blizzards hit the East Coast this winter, it proved to my satisfaction that global warming was a fraud. That snow was freezing cold. But in an alarming trend, temperatures this spring have risen. Consider this: On February <m>6^{th}</m> it was 10 degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So clearly folks the climate debate rages on.</em>
    </p>

    <p>
      Stephen Colbert
    </p>

    <p>
      April 6th, 2010 <fn>MISSINGoiRedirect</fn>
    </p>

    <p>
      Linear models can be used to approximate the relationship between two variables. However, these models have real limitations. Linear regression is simply a modeling framework. The truth is almost always much more complex than our simple line. For example, we do not know how the data outside of our limited window will behave.
    </p>

    <example>
      <statement>
        <p>
          Use the model <m>\widehat{aid} = 24.3 - 0.0431\times family\_income</m> to estimate the aid of another freshman student whose family had income of <dollar />1 million.
        </p>
      </statement>
      <answer>
        <p>
          Recall that the units of family income are in <dollar />1000s, so we want to calculate the aid for <m>family\_income = 1000</m>:
          <md>
            <mrow>\widehat{aid} \amp = 24.3 - 0.0431 \times family\_income</mrow>
            <mrow>\widehat{aid}\amp =24.3 - 0.431(1000) = -18.8</mrow>
          </md>
        </p>

        <p>
          The model predicts this student will have -<dollar />18,800 in aid (!). Elmhurst College cannot (or at least does not) require any students to pay extra on top of tuition to attend.
        </p>
      </answer>
    </example>

    <p>
      Applying a model estimate to values outside of the realm of the original data is called <term>extrapolation</term>. Generally, a linear model is only an approximation of the real relationship between two variables. If we extrapolate, we are making an unreliable bet that the approximate linear relationship will be valid in places where it has not been analyzed.
    </p>

    <p>
      <index><main>least squares regression</main><sub>extrapolation</sub></index>
    </p>
  </subsection>

  <subsection>
    <title>Using <m>R^2</m> to describe the strength of a fit</title>
    <p>
      <index><main>least squares regression</main><sub>R-squared (<m>R^2</m>)</sub></index>
    </p>

    <p>
      We evaluated the strength of the linear relationship between two variables earlier using the correlation coefficient, <m>r</m>. However, it is more common to explain the strength of a linear fit using <m>R^2</m>, called <em>R-squared</em><index><main>least squares regression</main><sub>R-squared (<m>R^2</m>)|textbf</sub></index> or the <term>explained variance</term>. If provided with a linear model, we might like to describe how closely the data cluster around the linear fit.
    </p>

    <figure xml:id="elmhurstScatterWLSROnly" >
      <caption>Gift aid and family income for a random sample of 50 freshman students from Elmhurst College, shown with the least squares regression line.</caption>
      <image width="75%" source="images/elmhurstScatterWLSROnly.png" />
    </figure>

    <p>
      The <m>R^2</m> of a linear model describes the amount of variation in the response that is explained by the least squares line. For example, consider the Elmhurst data, shown in <xref ref="elmhurstScatterWLSROnly">Figure</xref>. The variance of the response variable, aid received, is <m>s_{aid}^2=29.8</m>. However, if we apply our least squares line, then this model reduces our uncertainty in predicting aid using a student's family income. The variability in the residuals describes how much variation remains after using the model: <m>s_{_{RES}}^2 = 22.4</m>. In short, there was a reduction of
      <me>
        \frac{s_{aid}^2 - s_{_{RES}}^2}{s_{aid}^2}
          = \frac{29.8 - 22.4}{29.8} = \frac{7.5}{29.8}
          = 0.25
      </me>
    </p>

    <p>
      This is how we compute the <m>R^2</m> value.<fn><m>R^2=1-\frac{s^2_{RES}}{s^2_y}</m></fn> It also corresponds to the square of the correlation coefficient, <m>r</m>, that<nbsp />is, <m>R^2=r^2</m>.
      <md>
        <mrow>R^2 \amp = 0.25 \amp  r \amp = -0.499</mrow>
      </md>
    </p>

    <definition>
      <title>$R^2$ is the explained variance</title>
      <statement>
        <p>
          <m>R^2</m> is always between 0 and 1, inclusive. It tells us the proportion of variation in the <m>y</m> values that is explained by a regression model. The higher the value of <m>R^2</m>, the better the model <q>explains</q> the reponse variable.
        </p>
      </statement>
    </definition>

    <exercise>
      <statement>
        <p>
          If a linear model has a very strong negative relationship with a correlation of -0.97, how much of the variation in the response is explained by the explanatory variable?<fn>About <m>R^2 = (-0.97)^2 = 0.94</m> or 94<percent /> of the variation in aid is explained by the linear model.</fn>
          <index><main>least squares regression</main><sub>R-squared (<m>R^2</m>)</sub></index>
        </p>
      </statement>
    </exercise>
    <exercise>
      <statement>
        <p>
          If a linear model has an <m>R^2</m> or explained variance of 0.94, what is the correlation coefficient?<fn>We take the square root of <m>R^2</m> and get 0.97, but we must be careful, because <m>r</m> could be 0.97 <em>or</em> -0.97.  Without knowing the slope or seeing the scatterplot, we have no way of knowing if <m>r</m> is positive or negative.</fn>
        </p>
      </statement>
    </exercise>
  </subsection>

  <subsection>
    <title>Calculator: linear correlation and regression</title>
    <definition>
      <title>TI-84: finding $b_0$, $b_1$, $R^2$, and $r$ for a linear model</title>
      <statement>
        <p>
          MISSINGVIDEOLINK
          Use <c>STAT</c>, <c>CALC</c>, <c>LinReg(a + bx)</c>.
          <ol>
            <li>
              <p>
                Choose <c>STAT</c>.
              </p>
            </li>

            <li>
              <p>
                Right arrow to <c>CALC</c>.
              </p>
            </li>

            <li>
              <p>
                Down arrow and choose <c>8:LinReg(a+bx)</c>.
                <ul>
                  <li>
                    <p>
                      Caution: choosing <c>4:LinReg(ax+b)</c> will reverse <m>a</m> and <m>b</m>.
                    </p>
                  </li>
                </ul>
              </p>
            </li>

            <li>
              <p>
                Let <c>Xlist</c> be <c>L1</c> and <c>Ylist</c> be <c>L2</c> (don't forget to enter the <m>x</m> and <m>y</m> values in L1 and <c>L2</c> before doing this calculation).
              </p>
            </li>

            <li>
              <p>
                Leave <c>FreqList</c> blank.
              </p>
            </li>

            <li>
              <p>
                Leave <c>Store RegEQ</c> blank.
              </p>
            </li>

            <li>
              <p>
                Choose Calculate and hit <c>ENTER</c>, which returns:
                <tabular>
                  <row>
                    <cell><c>a</c></cell>
                    <cell><m>b_0</m>, the y-intercept of the best fit line</cell>
                  </row>
                  <row>
                    <cell><c>b</c></cell>
                    <cell><m>b_1</m>, the slope of the best fit line</cell>
                  </row>
                  <row>
                    <cell><m>\textttmath{r^2}</m></cell>
                    <cell><m>R^2</m>, the explained variance</cell>
                  </row>
                  <row>
                    <cell><c>r</c></cell>
                    <cell><m>r</m>, the correlation coefficient</cell>
                  </row>
                </tabular>
              </p>
            </li>
          </ol>
        </p>

        <p>
          TI-83: Do steps 1-3, then enter the <m>x</m> list and <m>y</m> list separated by a comma, e.g. <c>LinReg(a+bx) L1, L2</c>, then hit <c>ENTER</c>.
        </p>
      </statement>
    </definition>

    <aside>
      <title>What to do if $r^2$ and $r$ do not show up on a TI-83/84</title>
      <p>
        If <m>r^2</m> and <m>r</m> do now show up when doing <c>STAT</c>, <c>CALC</c>, <c>LinReg</c>, the <em>diagnostics</em> must be turned on. This only needs to be once and the diagnostics will remain on.
        <ol>
          <li>
            <p>
              Hit <c>2ND</c> <c>0</c> (i.e. <c>CATALOG</c>).
            </p>
          </li>

          <li>
            <p>
              Scroll down until the arrow points at <c>DiagnosticOn</c>.
            </p>
          </li>

          <li>
            <p>
              Hit <c>ENTER</c> and <c>ENTER</c> again. The screen should now say:
              <tabular>
                <row>
                  <cell><c>DiagnosticOn</c></cell>
                  <cell></cell>
                </row>
                <row>
                  <cell></cell>
                  <cell><c>Done</c></cell>
                </row>
              </tabular>
            </p>
          </li>
        </ol>
      </p>
    </aside>
    <aside>
      <title>What to do if a TI-83/84 returns: <c>ERR:</c><nbsp /><c>DIM MISMATCH</c></title>
      <p>
        This error means that the lists, generally L1 and L2, do not have the same length.
        <ol>
          <li>
            <p>
              Choose <c>1:Quit</c>.
            </p>
          </li>

          <li>
            <p>
              Choose <c>STAT</c>,<nbsp /><c>Edit</c> and make sure that the lists have the same number of entries.
            </p>
          </li>
        </ol>
      </p>
    </aside>
    <definition>
      <title>Casio fx-9750GII: finding $b_0$, $b_1$, $R^2$, and $r$ for a linear model</title>
      <statement>
        <p>
          MISSINGVIDEOLINK
          <ol>
            <li>
              <p>
                Navigate to <c>STAT</c> (<c>MENU</c> button, then hit the <c>2</c> button or select <c>STAT</c>).
              </p>
            </li>

            <li>
              <p>
                Enter the <m>x</m> and <m>y</m> data into 2 separate lists, e.g. <m>x</m> values in <c>List 1</c> and <m>y</m> values in <c>List 2</c>. Observation ordering should be the same in the two lists. For example, if <m>(5, 4)</m> is the second observation, then the second value in the <m>x</m> list should be 5 and the second value in the <m>y</m> list should be 4.
              </p>
            </li>

            <li>
              <p>
                Navigate to <c>CALC</c> (<c>F2</c>) and then <c>SET</c> (<c>F6</c>) to set the regression context.
                <ul>
                  <li>
                    <p>
                      To change the <c>2Var XList</c>, navigate to it, select <c>List</c> (<c>F1</c>), and enter the proper list number. Similarly, set <c>2Var YList</c> to the proper list.
                    </p>
                  </li>
                </ul>
              </p>
            </li>

            <li>
              <p>
                Hit <c>EXIT</c>.
              </p>
            </li>

            <li>
              <p>
                Select <c>REG</c> (<c>F3</c>), <c>X</c> (<c>F1</c>), and <c>a+bx</c> (<c>F2</c>), which returns:
                <tabular>
                  <row>
                    <cell><c>a</c></cell>
                    <cell><m>b_0</m>, the y-intercept of the best fit line</cell>
                  </row>
                  <row>
                    <cell><c>b</c></cell>
                    <cell><m>b_1</m>, the slope of the best fit line</cell>
                  </row>
                  <row>
                    <cell><c>r</c></cell>
                    <cell><m>r</m>, the correlation coefficient</cell>
                  </row>
                  <row>
                    <cell><m>\textttmath{r^2}</m></cell>
                    <cell><m>R^2</m>, the explained variance</cell>
                  </row>
                  <row>
                    <cell><c>MSe</c></cell>
                    <cell>Mean squared error, which you can ignore</cell>
                  </row>
                </tabular>
                If you select <c>ax+b</c> (<c>F1</c>), the <c>a</c> and <c>b</c> meanings will be reversed.
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </definition>

    <table xml:id="subsetOfCountyForRegression" >
      <caption>Data for Guided <xref ref="subsetOfCountyForRegressionGP">Practice</xref>.</caption>
      {
      <tabular>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell></cell>
          <cell><c>fed_spend</c></cell>
          <cell><c>poverty</c></cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>1</cell>
          <cell>6.07</cell>
          <cell>10.6</cell>
        </row>
        <row>
          <cell>2</cell>
          <cell>6.14</cell>
          <cell>12.2</cell>
        </row>
        <row>
          <cell>3</cell>
          <cell>8.75</cell>
          <cell>25.0</cell>
        </row>
        <row>
          <cell>4</cell>
          <cell>7.12</cell>
          <cell>12.6</cell>
        </row>
        <row>
          <cell>5</cell>
          <cell>5.13</cell>
          <cell>13.4</cell>
        </row>
        <row>
          <cell>6</cell>
          <cell>8.71</cell>
          <cell>5.6</cell>
        </row>
        <row>
          <cell>7</cell>
          <cell>6.70</cell>
          <cell>7.9</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
      </tabular>
      }
    </table>

    <exercise xml:id="subsetOfCountyForRegressionGP">
      <statement>
        <p>
          <xref ref="subsetOfCountyForRegression">Table</xref> contains values of federal spending per capita (rounded to the nearand percent of population in poverty for seven counties. This is a subset of the <c>countyDF</c> data set from Chapter 1. Use a calculator to find the equation of the least squares regression line for this partial data set.<fn><m>a=5.136</m> and <m>b=1.056</m>, therefore <m>\hat{y}=5.136 + 1.056x</m>.</fn>
        </p>
      </statement>
    </exercise>
  </subsection>

  <subsection xml:id="categoricalPredictorsWithTwoLevels">
    <title>Categorical predictors with two levels (special topic)</title>
    <p>
      Categorical variables are also useful in predicting outcomes. Here we consider a categorical predictor with two levels (recall that a <em>level</em> is the same as a <em>category</em>). We'll consider Ebay auctions for a video game, <em>Mario Kart</em> for the Nintendo Wii, where both the total price of the auction and the condition of the game were recorded.<fn>These data were collected in Fall 2009 and may be found at MISSINGoiRedirect.</fn> Here we want to predict total price based on game condition, which takes values <c>used</c> and <c>new</c>. A plot of the auction data is shown in <xref ref="marioKartNewUsed">Figure</xref>.
    </p>

    <figure xml:id="marioKartNewUsed" >
      <caption>Total auction prices for the video game <em>Mario Kart</em>, divided into used (<m>x=0</m>) and new (<m>x=1</m>) condition games. The least squares regression line is also shown.</caption>
      <image width="60%" source="images/marioKartNewUsed.png" />
    </figure>

    <p>
      To incorporate the game condition variable into a regression equation, we must convert the categories into a numerical form. We will do so using an <term>indicator variable</term> called <c>cond_new</c>, which takes value 1 when the game is new and 0 when the game is used. Using this indicator variable, the linear model may be written as
      <md>
        <mrow>\widehat{price} = \beta_0 + \beta_1 \times \text{\texttt{cond\_new}}</mrow>
      </md>
    </p>

    <p>
      The fitted model is summarized in <xref ref="marioKartNewUsedRegrSummary">Table</xref>, and the model with its parameter estimates is given as
      <md>
        <mrow>\widehat{price} = 42.87 + 10.90 \times \text{\texttt{cond\_new}}</mrow>
      </md>
    </p>

    <p>
      For categorical predictors with just two levels, the linearity assumption will always be satisfied. However, we must evaluate whether the residuals in each group are approximately normal and have approximately equal variance. As can be seen in <xref ref="marioKartNewUsed">Figure</xref>, both of these conditions are reasonably satisfied by the auction data.
    </p>

    <table xml:id="marioKartNewUsedRegrSummary" >
      <caption>Least squares regression summary for the final auction price against the condition of the game.</caption>
      <tabular>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-3.7mm}</cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell></cell>
          <cell>Estimate</cell>
          <cell>Std. Error</cell>
          <cell>t value</cell>
          <cell>Pr(<m>></m><m>|</m>t<m>|</m>)</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>\vspace{-3.6mm}</cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
        <row>
          <cell>(Intercept)</cell>
          <cell>42.87</cell>
          <cell>0.81</cell>
          <cell>52.67</cell>
          <cell>0.0000</cell>
        </row>
        <row>
          <cell>cond_new</cell>
          <cell>10.90</cell>
          <cell>1.26</cell>
          <cell>8.66</cell>
          <cell>0.0000</cell>
        </row>
        <row bottom="minor">
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
          <cell></cell>
        </row>
      </tabular>
    </table>

    <example>
      <statement>
        <p>
          Interpret the two parameters estimated in the model for the price of <em>Mario Kart</em> in eBay auctions.
        </p>
      </statement>
      <answer>
        <p>
          The intercept is the estimated price when <c>cond_new</c> takes value 0, i.e. when the game is in used condition. That is, the average selling price of a used version of the game is <dollar />42.87.
        </p>

        <p>
          The slope indicates that, on average, new games sell for about <dollar />10.90 more than used games.
        </p>
      </answer>
    </example>

    <aside>
      <title>Interpreting model estimates for categorical predictors.</title>
      <p>
        The estimated intercept is the value of the response variable for the first category (i.e. the category corresponding to an indicator value of 0). The estimated slope is the average change in the response variable between the two categories.
      </p>
    </aside>
  </subsection>
</section>
